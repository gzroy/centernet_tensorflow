{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "imageHeight = 512\n",
    "imageWidth = 512\n",
    "\n",
    "sigma = 0.06\n",
    "focal_alpha = 2\n",
    "focal_beta = 4\n",
    "lambda_size = 0.1\n",
    "lambda_offset = 1.0\n",
    "\n",
    "filterDim = [256, 384, 384, 384, 512]\n",
    "\n",
    "resize_width = 550\n",
    "resize_height = 550\n",
    "image_width = 512\n",
    "image_height = 512\n",
    "image_width_delta = resize_width - image_width\n",
    "image_height_delta = resize_height - image_height \n",
    "batch_size = 3\n",
    "valid_batch_size = 1\n",
    "epoch_size = 26332\n",
    "category_num = 80\n",
    "jitter = 0.3\n",
    "vector_size = 1+4+category_num\n",
    "label_vector_size = 1+4+category_num\n",
    "labels = ['umbrella',\n",
    " 'sandwich',\n",
    " 'handbag',\n",
    " 'person',\n",
    " 'snowboard',\n",
    " 'cell phone',\n",
    " 'traffic light',\n",
    " 'potted plant',\n",
    " 'toaster',\n",
    " 'baseball glove',\n",
    " 'cow',\n",
    " 'surfboard',\n",
    " 'remote',\n",
    " 'toilet',\n",
    " 'baseball bat',\n",
    " 'giraffe',\n",
    " 'book',\n",
    " 'bottle',\n",
    " 'stop sign',\n",
    " 'frisbee',\n",
    " 'boat',\n",
    " 'sheep',\n",
    " 'mouse',\n",
    " 'motorcycle',\n",
    " 'car',\n",
    " 'bird',\n",
    " 'pizza',\n",
    " 'bed',\n",
    " 'kite',\n",
    " 'zebra',\n",
    " 'broccoli',\n",
    " 'cat',\n",
    " 'chair',\n",
    " 'bench',\n",
    " 'teddy bear',\n",
    " 'tennis racket',\n",
    " 'laptop',\n",
    " 'sink',\n",
    " 'sports ball',\n",
    " 'skateboard',\n",
    " 'parking meter',\n",
    " 'carrot',\n",
    " 'hair drier',\n",
    " 'banana',\n",
    " 'wine glass',\n",
    " 'scissors',\n",
    " 'spoon',\n",
    " 'cake',\n",
    " 'fire hydrant',\n",
    " 'dog',\n",
    " 'backpack',\n",
    " 'airplane',\n",
    " 'clock',\n",
    " 'keyboard',\n",
    " 'truck',\n",
    " 'bicycle',\n",
    " 'skis',\n",
    " 'bus',\n",
    " 'hot dog',\n",
    " 'dining table',\n",
    " 'cup',\n",
    " 'toothbrush',\n",
    " 'horse',\n",
    " 'elephant',\n",
    " 'refrigerator',\n",
    " 'knife',\n",
    " 'suitcase',\n",
    " 'apple',\n",
    " 'donut',\n",
    " 'couch',\n",
    " 'train',\n",
    " 'microwave',\n",
    " 'bear',\n",
    " 'oven',\n",
    " 'bowl',\n",
    " 'orange',\n",
    " 'tv',\n",
    " 'tie',\n",
    " 'vase',\n",
    " 'fork']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _label_fn(bbox):\n",
    "    stride_height = image_height//4\n",
    "    stride_width = image_width//4\n",
    "    labels = np.zeros((stride_height, stride_width, label_vector_size)) \n",
    "    box_num, _ = bbox.shape\n",
    "    index_x = np.tile(range(stride_width), (stride_height,1))\n",
    "    index_y = np.transpose(index_x)\n",
    "    for i in range(box_num):\n",
    "        center_y = int(bbox[i,0]/4)\n",
    "        center_x = int(bbox[i,1]/4)\n",
    "        box_height = bbox[i,2]/4\n",
    "        box_width = bbox[i,3]/4\n",
    "        box_size = box_height*box_width\n",
    "        category = bbox[i,4]\n",
    "        truth = np.exp(-(np.square(index_x-center_x)+np.square(index_y-center_y))/(2*sigma*box_size))\n",
    "        labels[:,:,category] = np.maximum(truth, labels[:,:,category])\n",
    "        labels[center_y,center_x,-5] = 1.0\n",
    "        labels[center_y,center_x,-4] = float(box_height)\n",
    "        labels[center_y,center_x,-3] = float(box_width)\n",
    "        labels[center_y,center_x,-2] = bbox[i,0]/4 - center_y\n",
    "        labels[center_y,center_x,-1] = bbox[i,1]/4 - center_x\n",
    "    return labels.astype(np.float32)\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    features = {\"image\": tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "                \"height\": tf.FixedLenFeature([1], tf.int64, default_value=[0]),\n",
    "                \"width\": tf.FixedLenFeature([1], tf.int64, default_value=[0]),\n",
    "                \"channels\": tf.FixedLenFeature([1], tf.int64, default_value=[3]),\n",
    "                \"colorspace\": tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "                \"img_format\": tf.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "                \"label\": tf.VarLenFeature(tf.int64),\n",
    "                \"bbox_xmin\": tf.VarLenFeature(tf.int64),\n",
    "                \"bbox_xmax\": tf.VarLenFeature(tf.int64),\n",
    "                \"bbox_ymin\": tf.VarLenFeature(tf.int64),\n",
    "                \"bbox_ymax\": tf.VarLenFeature(tf.int64),\n",
    "                \"filename\": tf.FixedLenFeature([], tf.string, default_value=\"\")\n",
    "               }\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    \n",
    "    label = tf.expand_dims(parsed_features[\"label\"].values, 0)\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    height = tf.squeeze(tf.cast(parsed_features[\"height\"], tf.int32))\n",
    "    width = tf.squeeze(tf.cast(parsed_features[\"width\"], tf.int32))\n",
    "    channels = parsed_features[\"channels\"]\n",
    "    filename = tf.expand_dims(parsed_features[\"filename\"],0)\n",
    "    #Get the bbox\n",
    "    xmin = tf.cast(tf.expand_dims(parsed_features[\"bbox_xmin\"].values, 0), tf.int32)\n",
    "    xmax = tf.cast(tf.expand_dims(parsed_features[\"bbox_xmax\"].values, 0), tf.int32)\n",
    "    ymin = tf.cast(tf.expand_dims(parsed_features[\"bbox_ymin\"].values, 0), tf.int32)\n",
    "    ymax = tf.cast(tf.expand_dims(parsed_features[\"bbox_ymax\"].values, 0), tf.int32)\n",
    "\n",
    "    boxes = tf.concat([xmin,ymin,xmax,ymax], axis=0)\n",
    "    boxes = tf.transpose(boxes, [1, 0])\n",
    "    #Decode the image\n",
    "    image_raw = tf.image.decode_jpeg(parsed_features[\"image\"], channels=3)\n",
    "    image_decoded = tf.image.convert_image_dtype(image_raw, tf.float32)\n",
    "    \n",
    "    dw = jitter*tf.cast(width, tf.float32)\n",
    "    dh = jitter*tf.cast(height, tf.float32)\n",
    "    new_ar = tf.truediv(tf.add(tf.cast(width, tf.float32), tf.random.uniform([1], minval=tf.math.negative(dw), maxval=dw)), \\\n",
    "                        tf.add(tf.cast(height, tf.float32), tf.random.uniform([1], minval=tf.math.negative(dh), maxval=dh)))\n",
    "    nh, nw = tf.cond(tf.less(new_ar[0],1), \\\n",
    "                     lambda:(image_height, tf.cast(tf.cast(image_height, tf.float32)*new_ar[0], tf.int32)), \\\n",
    "                     lambda:(tf.cast(tf.cast(image_width, tf.float32)/new_ar[0], tf.int32), image_width))\n",
    "    dx = tf.cond(tf.equal(image_width, nw), \\\n",
    "                 lambda:tf.constant([0]), \\\n",
    "                 lambda:tf.random.uniform([1], minval=0, maxval=(image_width-nw), dtype=tf.int32))\n",
    "    dy = tf.cond(tf.equal(image_height, nh), \\\n",
    "                 lambda:tf.constant([0]), \\\n",
    "                 lambda:tf.random.uniform([1], minval=0, maxval=(image_height-nh), dtype=tf.int32))\n",
    "    #image_resize = tf.image.per_image_standardization(tf.image.resize(image_decoded, [nh, nw]))\n",
    "    image_distort = tf.image.resize(image_decoded, [nh, nw])\n",
    "    #image_distort = distort_color(image_resize)\n",
    "    image_padded = tf.image.pad_to_bounding_box(image_distort, dy[0], dx[0], image_height, image_width)\n",
    "\n",
    "    #Adjust the boxes\n",
    "    xmin_new = tf.cast(tf.truediv(nw, width) * tf.cast(xmin,tf.float64), tf.int32) + dx\n",
    "    xmax_new = tf.cast(tf.truediv(nw, width) * tf.cast(xmax,tf.float64), tf.int32) + dx\n",
    "    ymin_new = tf.cast(tf.truediv(nh, height) * tf.cast(ymin,tf.float64), tf.int32) + dy\n",
    "    ymax_new = tf.cast(tf.truediv(nh, height) * tf.cast(ymax,tf.float64), tf.int32) + dy\n",
    "    boxes_width = xmax_new-xmin_new\n",
    "    boxes_height = ymax_new-ymin_new\n",
    "    boxes_area = boxes_width*boxes_height\n",
    "    \n",
    "    # Random flip flag\n",
    "    random_flip_flag = tf.random.uniform([1], minval=0, maxval=1, dtype=tf.float32)\n",
    "    def flip_box():\n",
    "        xmax_flip = image_width - xmin_new\n",
    "        xmin_flip = image_width - xmax_new\n",
    "        image_flip = tf.image.flip_left_right(image_padded)\n",
    "        return xmin_flip, xmax_flip, image_flip\n",
    "    def notflip():\n",
    "        return xmin_new, xmax_new, image_padded\n",
    "    xmin_flip, xmax_flip, image_flip = tf.cond(tf.less(random_flip_flag[0], 0.5), notflip, flip_box)\n",
    "    center_x = xmin_flip + (xmax_flip-xmin_flip)//2\n",
    "    center_y = ymin_new + (ymax_new-ymin_new)//2\n",
    "    boxes_new = tf.concat([center_y,center_x,(ymax_new-ymin_new),(xmax_flip-xmin_flip),label], axis=0)\n",
    "    boxes_new = tf.transpose(boxes_new, [1, 0])\n",
    "    \n",
    "    label_new = tf.py_func(_label_fn, [boxes_new], tf.float32)\n",
    "    \n",
    "    return image_flip, boxes_new, label_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    train_files = tf.data.Dataset.list_files(\"coco/train_10.tfrecord\")\n",
    "    dataset_train = train_files.interleave(tf.data.TFRecordDataset, cycle_length=4, num_parallel_calls=4)\n",
    "    dataset_train = dataset_train.shuffle(buffer_size=epoch_size)\n",
    "    dataset_train = dataset_train.repeat(100)\n",
    "    dataset_train = dataset_train.map(_parse_function, num_parallel_calls=12)\n",
    "    dataset_train = dataset_train.padded_batch(batch_size, \\\n",
    "                                               padded_shapes=([None,None, None], [None, None], [None, None, None]))\n",
    "    dataset_train = dataset_train.prefetch(batch_size)\n",
    "    iterator = tf.data.Iterator.from_structure(dataset_train.output_types, dataset_train.output_shapes)\n",
    "    image_augment, bbox_result, label_result = iterator.get_next()\n",
    "    train_init_op = iterator.make_initializer(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Equal:0' shape=(?, ?, ?, ?) dtype=bool>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.equal(label_test,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = label_result[:,:,:,:80]\n",
    "labels_obj_mask = tf.equal(label_test,1.0)\n",
    "labels_noobj_mask = tf.less(label_test,1.0)\n",
    "labels_obj = tf.boolean_mask(label_test, labels_obj_mask)\n",
    "labels_noobj = tf.boolean_mask(label_test, labels_noobj_mask)\n",
    "#preds_obj_k = tf.boolean_mask(labels, labels_obj_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(train_init_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, bbox, label, label_1, label_2, mask1 = sess.run([image_augment, bbox_result, label_result, labels_obj, labels_noobj, labels_obj_mask])\n",
    "#image, label = sess.run([image_augment, label_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[236, 200, 141,  61,   3],\n",
       "        [210, 134,  36,  86,  33],\n",
       "        [224, 238,  28,  55,  35],\n",
       "        [193, 251,  18,  46,  33],\n",
       "        [185, 359,   4,  25,  33],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0]],\n",
       "\n",
       "       [[375,  81,  33,  94,  54],\n",
       "        [372, 152,  21,  47,  54],\n",
       "        [370, 396,  18,  49,  20],\n",
       "        [358, 315,  42,  29,  20],\n",
       "        [358, 288,  43,  32,  20],\n",
       "        [365, 263,  26,  24,  20],\n",
       "        [398, 234,  25,  28,  20],\n",
       "        [366, 450,  19,  40,  20],\n",
       "        [364, 358,  22,  21,  20],\n",
       "        [367, 338,  20,  20,  20],\n",
       "        [370, 249,  12,   9,  20],\n",
       "        [361, 244,  18,  25,  20],\n",
       "        [366, 479,  10,  38,  20],\n",
       "        [289, 500,   7,  12,  25],\n",
       "        [302, 471,   5,  10,  25],\n",
       "        [359, 368,  17,  25,  20],\n",
       "        [282, 289,   7,   6,  25],\n",
       "        [287, 367,   7,   6,  25],\n",
       "        [369, 420,  13,  24,  20],\n",
       "        [301, 138,   4,   4,  25],\n",
       "        [355, 211,  36,  63,  20]],\n",
       "\n",
       "       [[383, 230, 190, 152,   3],\n",
       "        [349, 152,  19,  24,  19],\n",
       "        [377, 247, 198, 175,   3],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0]]], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3932131,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=128*128*80*3\n",
    "b=a-3932131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3932160"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 128, 128, 80)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[0,41,100,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_bbox = bbox[0]\n",
    "for i in range(image_bbox.shape[0]):\n",
    "    cv2.rectangle(image[0], (image_bbox[i][0],image_bbox[i][1]), (image_bbox[i][2],image_bbox[i][3]), (0,255,0), 2)\n",
    "\n",
    "plt.imshow(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encpasulate the conv and residual functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = tf.keras.layers\n",
    "def _conv(inputs, filters, kernel_size, strides, padding, bias=False, normalize=True, activation='relu'):\n",
    "    output = inputs\n",
    "    padding_str = 'same'\n",
    "    if padding>0:\n",
    "        output = l.ZeroPadding2D(padding=padding)(output)\n",
    "        padding_str = 'valid'\n",
    "    output = l.Conv2D(filters, kernel_size, strides, padding_str, use_bias=bias, \\\n",
    "                 kernel_initializer='he_normal', \\\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l=5e-4))(output)\n",
    "    if normalize:\n",
    "        output = l.BatchNormalization(axis=3)(output)\n",
    "    if activation=='relu':\n",
    "        output = l.ReLU()(output)\n",
    "    if activation=='relu6':\n",
    "        output = l.ReLU(max_value=6)(output)\n",
    "    if activation=='leaky_relu':\n",
    "        output = l.LeakyReLU(alpha=0.1)(output)\n",
    "    if activation=='sigmoid':\n",
    "        output = tf.keras.activations.sigmoid(output)\n",
    "    return output\n",
    "\n",
    "def _residual(inputs, filters, strides):\n",
    "    shortcut = inputs\n",
    "    num_channels = shortcut.get_shape().as_list()[-1]\n",
    "    output = _conv(inputs, filters, 3, 2, 1)\n",
    "    output = _conv(output, filters, 3, 1, 0, False, True, 'linear')\n",
    "    if num_channels != filters or strides != 1:\n",
    "        shortcut = _conv(shortcut, filters, 1, strides, 0, False, Ture, 'linear')\n",
    "    output = l.Add()([output, shortcut])\n",
    "    output = l.ReLU()(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hourglass function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hourglass(inputs, filterDim):\n",
    "    #Left part, left_features image dimension, 1,1/2,1/4,1/8,1/16,1/32\n",
    "    left_features = [inputs]\n",
    "    for index, dim in enumerate(filterDim):\n",
    "        output = _residual(left_features[-1], dim, 2)\n",
    "        output = _residual(output, dim, 1)\n",
    "        left_features.append(output)\n",
    "    #Middle part\n",
    "    output = left_features[-1]\n",
    "    for i in range(5):\n",
    "        output = _residual(output, filterDim[-1], 1)\n",
    "    #Right part\n",
    "    for index in reversed(range(len(filterDim))):\n",
    "        output = _residual(output, filterDim[index], 1)\n",
    "        output = _residual(output, filterDim[max(index-1, 0)], 1)\n",
    "        output = l.UpSampling2D()(output)\n",
    "        left_feature = _residual(left_features[index], filterDim[max(index-1, 0)], 1)\n",
    "        left_feature = _residual(left_feature, filterDim[max(index-1, 0)], 1)\n",
    "        output = l.Add()([output, left_feature])\n",
    "    output = _conv(output, 256, 3, 1, 1)\n",
    "    outputs = [output]\n",
    "    #Prediction\n",
    "    pred_keypoints = _conv(output, 256, 3, 1, 0, True, False, 'relu') \n",
    "    pred_keypoints = _conv(pred_keypoints, 80, 1, 1, 0, True, False, 'sigmoid') \n",
    "    outputs.append(pred_keypoints)\n",
    "    pred_offset = _conv(output, 256, 3, 1, 0, True, False, 'relu') \n",
    "    pred_offset = _conv(pred_offset, 2, 1, 1, 0, True, False, 'linear') \n",
    "    outputs.append(pred_offset)\n",
    "    pred_size = _conv(output, 256, 3, 1, 0, True, False, 'relu') \n",
    "    pred_size = _conv(pred_size, 2, 1, 1, 0, True, False, 'linear') \n",
    "    outputs.append(pred_size)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the base hourglass network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HourglassNetwork():\n",
    "    image = tf.keras.Input(shape=(imageHeight,imageWidth,3))   #512×512×3\n",
    "    net = _conv(image, 128, 7, 2, 3)    #256×256×128\n",
    "    net = _residual(net, 256, 2)        #128×128×256\n",
    "    outputs_1 = _hourglass(net, filterDim)\n",
    "    outputs_2 = _hourglass(outputs_1[0], filterDim)\n",
    "    model = tf.keras.Model(inputs=image, outputs=(outputs_1+outputs_2))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(preds, labels):\n",
    "    labels_offset_size = labels[...,80:]\n",
    "    labels_offset_size_mask = tf.equal(labels_offset_size[...,0],1.0)\n",
    "    labels_offset_size_obj = tf.boolean_mask(labels_offset_size, labels_offset_size_mask)\n",
    "    obj_num = tf.cast(labels_offset_size_obj.shape[0], tf.float32)\n",
    "    preds_offset = preds[1]\n",
    "    preds_offset_obj = tf.boolean_mask(preds_offset, labels_offset_size_mask)\n",
    "    loss_offset = tf.math.truediv(\\\n",
    "                      tf.reduce_sum(\\\n",
    "                          tf.math.abs(\\\n",
    "                              preds_offset_obj-labels_offset_size_obj[...,1:3])),\n",
    "                      obj_num)\n",
    "    preds_size = preds[2]\n",
    "    preds_size_obj = tf.boolean_mask(preds_size, labels_offset_size_mask)\n",
    "    loss_size = tf.math.truediv(\\\n",
    "                      tf.reduce_sum(\\\n",
    "                          tf.math.abs(\\\n",
    "                              preds_size_obj-labels_offset_size_obj[...,3:])),\n",
    "                      obj_num\n",
    "    labels_k = labels[...,:80]\n",
    "    labels_k_obj_mask = tf.equal(labels_k, 1.0)\n",
    "    labels_k_noobj_mask = tf.less(labels_k, 1.0)\n",
    "    labels_k_obj = tf.boolean_mask(labels_k, labels_k_obj_mask)\n",
    "    labels_k_noobj = tf.boolean_mask(labels_k, labels_k_noobj_mask)\n",
    "    preds_k_obj = tf.boolean_mask(preds[0], labels_k_obj_mask)\n",
    "    preds_k_noobj = tf.boolean_mask(preds[0], labels_k_noobj_mask)\n",
    "    loss_k_obj = tf.reduce_sum(\\\n",
    "                     tf.math.multiply(\\\n",
    "                         tf.math.pow((1.0-preds_k_obj), focal_alpha),\\\n",
    "                         tf.math.log(preds_k_obj)))\n",
    "    loss_k_noobj = tf.reduce_sum(\\\n",
    "                       tf.math.multiply(\\\n",
    "                           tf.math.multiply(\\\n",
    "                               tf.math.pow((1.0-labels_k_noobj), focal_beta),\n",
    "                               tf.math.pow(preds_k_noobj, focal_alpha)),\n",
    "                           tf.math.log(1.0-preds_k_noobj)))\n",
    "    loss_k = tf.truediv(\\\n",
    "                 (loss_k_obj+loss_k_noobj),\\\n",
    "                 obj_num) \n",
    "    loss = loss_k + lambda_size*loss_size + lambda_offset*loss_offset\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate the output to prediction bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(output):\n",
    "    keypoint, offset, size = output\n",
    "    keypoint_nms = l.MaxPool2D(3, 1, 'same')\n",
    "    keypoint_mask = tf.cast(tf.equal(keypoint, keypoint_nms), tf.float32)\n",
    "    keypoint = keypoint * keypoint_mask\n",
    "    batch, height, width, category = tf.shape(keypoint)\n",
    "    keypoint_flat = tf.reshape(keypoint, [batch, -1])\n",
    "    offset_flat = tf.reshape(offset, [batch, -1])\n",
    "    size_flat = tf.reshape(size, [batch, -1])\n",
    "    scores, indices = tf.math.top_k(keypoint_flat, k=100, sorted=True)\n",
    "    classes = tf.cast(indices%category, tf.int32)\n",
    "    indices = tf.cast(indices/category, tf.int32)\n",
    "    x = tf.cast(indices%width, tf.float32)\n",
    "    y = tf.cast(indices/height, tf.float32)\n",
    "    offset_pred = tf.gather(offset, indices)\n",
    "    size_pred = tf.gather(size, indices)\n",
    "    x = x + offset_pred[1]\n",
    "    y = y + offset_pred[0]\n",
    "    xmin = x - size_pred[1]/2\n",
    "    xmax = x + size_pred[1]/2\n",
    "    ymin = y - size_pred[0]/2\n",
    "    ymax = y + size_pred[0]/2\n",
    "                                \n",
    "def CenterModel(features, labels, mode, params):\n",
    "    model = HourglassNetwork()\n",
    "    training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    images = tf.reshape(features[\"images\"], [-1, imageHeight, imageWidth, 3])\n",
    "    outputs = model(images, training)\n",
    " \n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=-1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    " \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, \\\n",
    "                                          export_outputs={'classify': tf.estimator.export.PredictOutput(predictions)})\n",
    " \n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss_inter = loss_fn(outputs[1:4], labels)\n",
    "    loss_final = loss_fn(outputs[5:], labels)\n",
    "    loss = loss_inter + loss_final\n",
    " \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        boundaries = [5000, 60000, 80000]\n",
    "        values = [0.1, 0.01, 0.001, 0.0001]\n",
    "        learning_rate = tf.compat.v1.train.piecewise_constant(global_step, boundaries, values)\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(model.get_updates_for(features)):\n",
    "            train_op = optimizer.minimize(loss=loss, global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    " \n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    m = tf.keras.metrics.sparse_top_k_categorical_accuracy(y_true=labels,  y_pred=logits)\n",
    "    tf.summary.scalar('top-5_accuracy', m)\n",
    "    accuracy = tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])\n",
    "    tf.summary.scalar('accuracy', accuracy[0]) \n",
    "    eval_metric_ops = {\n",
    "        #\"accuracy\": tf.metrics.accuracy(labels=true_labels, predictions=predictions[\"classes\"])}\n",
    "        \"accuracy\": accuracy} \n",
    "        #\"top-5 accuracy\": (m.result(), m.update_state(y_true=labels, y_pred=logits))}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_str = 'center.' * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [256, 384, 384, 384, 512]\n",
    "for kk in reversed(range(len(dims))):\n",
    "    print(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[2,3,5]\n",
    "b=[3,5,3]\n",
    "c=a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
